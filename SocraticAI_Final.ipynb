{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uGiTeA3XD3i"
      },
      "source": [
        "# SocraticAI\n",
        "\n",
        "Instructions:\n",
        "\n",
        "\n",
        "1. Upload your OpenAI API Key via a txt file labeled 'OpenAI_API_KEY.txt'\n",
        "2.   Upload your PDF reading that you want to talk to via socratic dialogue\n",
        "3.   Run all of the cells in this section\n",
        "4.   Run the code block in the Front End section, then click the Gradio link generated.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9Ple8kfB0qy"
      },
      "outputs": [],
      "source": [
        "!pip install PyPDF2\n",
        "!pip install tiktoken\n",
        "!pip install nest-asyncio\n",
        "!pip install aiohttp\n",
        "!pip install asyncinit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "I79d5TjeB28L"
      },
      "outputs": [],
      "source": [
        "from PyPDF2 import PdfReader\n",
        "import tiktoken\n",
        "import requests\n",
        "import aiohttp\n",
        "import asyncio\n",
        "import nest_asyncio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "D4RT9dq9nQq_"
      },
      "outputs": [],
      "source": [
        "f = open(\"OpenAI_API_KEY.txt\", \"r\")\n",
        "OPENAI_API_KEY = f.read()\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1nPwdW-TBYIr"
      },
      "outputs": [],
      "source": [
        "class PDFOutline:\n",
        "  def __init__(self, path):\n",
        "    #read PDF\n",
        "    self.fake_word_rate = 400\n",
        "\n",
        "    print(self._read_PDF(path))\n",
        "\n",
        "    big_string = \"\".join(self._read_PDF(path))\n",
        "    words = big_string.split(\" \")\n",
        "    self.pages = [\" \".join(words[i:min(i+self.fake_word_rate, len(words))]) for i in range(0, len(words), self.fake_word_rate)]\n",
        "\n",
        "    self.original_word_rate = (len(words) / len(self._read_PDF(path))) \n",
        "\n",
        "    #construct summaries in parallel\n",
        "    asyncio.run(self.parallel_summary(self.pages, 28))\n",
        "   \n",
        "    #construct outline\n",
        "    self.outline = self._outline(self.page_summaries, 1)\n",
        "\n",
        "  async def call_API(self, session, page, ratio, prev, sub):\n",
        "      MAX_TOKENS = 4096\n",
        "\n",
        "      #construct zero-shot summary prompt\n",
        "      summary_prompt = \"You are an expert summarizer. You will be provided a excerpt representing the contents of a current page from a text. You will also be provided the text of the pages directly before and after the excerpt. Summarize the excerpt. You can use the previous and subsequent pages to help contextualize the content on the current page. Please make sure to include all important key phrases in your summary.\"     \n",
        "      user_prompt = f\"Current page excerpt: {page}\\nPrevious page excerpt: {prev}\\nSubsequent page excerpt: {sub}\"\n",
        "      messages = [{\"role\": \"system\", \"content\": summary_prompt}, {\"role\": \"user\", \"content\": user_prompt}]\n",
        "      answer_length = MAX_TOKENS - self._num_tokens_from_string(summary_prompt) - self._num_tokens_from_string(user_prompt) - 50\n",
        "\n",
        "      #query the model\n",
        "      headers = {\"Authorization\": f\"Bearer {OPENAI_API_KEY}\",\n",
        "                \"content-type\": \"application/json\"}  \n",
        "      params = {\"model\": \"gpt-3.5-turbo\", \"messages\": messages, \"max_tokens\": answer_length // ratio}\n",
        "    \n",
        "      async with session.post(url=\"https://api.openai.com/v1/chat/completions\", json=params, headers=headers) as response:\n",
        "        result_data = await response.json()\n",
        "        try:\n",
        "          summary = result_data[\"choices\"][0][\"message\"][\"content\"]\n",
        "          return summary\n",
        "        except Exception as e:\n",
        "          print(e)\n",
        "          print(result_data)\n",
        "          print(self._num_tokens_from_string(user_prompt))\n",
        "          #print(page)\n",
        "          #print(prev)\n",
        "          #print(sub)\n",
        "\n",
        "  async def parallel_summary(self, pages, ratio):\n",
        "    async with aiohttp.ClientSession() as session:\n",
        "        tasks = []\n",
        "        if len(self.pages) == 1:\n",
        "          tasks.append(self.call_API(session, self.pages[0], ratio, \"Not applicable because this is the first page.\", \"Not applicable because this is the last page.\"))\n",
        "        else:\n",
        "          tasks.append(self.call_API(session, self.pages[0], ratio, \"Not applicable because this is the first page.\", self.pages[1]))\n",
        "          for num, page in enumerate(self.pages[1:-1]):\n",
        "            tasks.append(self.call_API(session, page, ratio, self.pages[num], self.pages[num+2])) #35 is arbitrary here. I needed to experiment with a couple different ratios to find the idea one\n",
        "          tasks.append(self.call_API(session, self.pages[-1], ratio, self.pages[-2], \"Not applicable because this is the last page.\"))\n",
        "\n",
        "        page_summaries = await asyncio.gather(*tasks)\n",
        "        self.page_summaries = {k: v for k, v in enumerate(page_summaries)}\n",
        "  \n",
        "  def _read_PDF(self, path):\n",
        "    reader = PdfReader(path)\n",
        "    return [page.extract_text() for page in reader.pages]\n",
        "\n",
        "  def _num_tokens_from_string(self, string: str) -> int:\n",
        "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
        "    encoding = tiktoken.get_encoding(\"p50k_base\") #encoding for text-davinci-003\n",
        "    num_tokens = len(encoding.encode(string))\n",
        "    return num_tokens\n",
        "\n",
        "  def _summarize(self, text, ratio, prev, sub):\n",
        "    #define CRFM API setting arguments\n",
        "    MODEL = \"openai/text-davinci-003\"\n",
        "    MAX_TOKENS = 4096\n",
        "\n",
        "    #construct zero-shot summary prompt\n",
        "    summary_prompt = \"You are an expert summarizer. You will be provided a excerpt representing the contents of a current page from a text. You will also be provided the text of the pages directly before and after the excerpt. Summarize the excerpt. You can use the previous and subsequent pages to help contextualize the content on the current page. Please make sure to include all important key phrases in your summary.\"     \n",
        "    user_prompt = f\"Current page excerpt: {text}\\nPrevious page excerpt: {prev}\\nSubsequent page excerpt: {sub}\"\n",
        "    messages = [{\"role\": \"system\", \"content\": summary_prompt}, {\"role\": \"user\", \"content\": user_prompt}]\n",
        "    answer_length = MAX_TOKENS - self._num_tokens_from_string(summary_prompt) - self._num_tokens_from_string(user_prompt) - 50\n",
        "\n",
        "    #query the model\n",
        "    headers = {\"Authorization\": f\"Bearer {OPENAI_API_KEY}\",\n",
        "               \"content-type\": \"application/json\"}  \n",
        "    params = {\"model\": \"gpt-3.5-turbo\", \"messages\": messages, \"max_tokens\": answer_length // ratio}\n",
        "\n",
        "    r = requests.post(url=\"https://api.openai.com/v1/chat/completions\", json=params, headers=headers)\n",
        "    \n",
        "    try:\n",
        "      return r.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "    except:\n",
        "      print(r.json())\n",
        "      print(self._num_tokens_from_string(user_prompt))\n",
        "  \n",
        "\n",
        "  def _outline(self, page_summaries, ratio):\n",
        "    MAX_TOKENS = 4096\n",
        "\n",
        "    #construct zero-shot outline prompt\n",
        "    outline_prompt = \"You are a world class text outliner. The following text contains page by page summaries from a PDF document. The summaries are provided in the form {[page number]: [summary]}. Write an organized outline (a ,b, c, each with subpoints) for the entire PDF document. Make sure to synthesize the main themes across the pages. Aim for a more compact outline. Don't provide pagae numbers. Get right into the outlineâ€“do not make any comments first.\"\n",
        "    user_prompt = str(page_summaries)\n",
        "    messages = [{\"role\": \"system\", \"content\": outline_prompt}, {\"role\": \"user\", \"content\": user_prompt}, {\"role\": \"assistant\", \"content\": \"Ok, here is the synthesized outline with page numbers.\"}]\n",
        "\n",
        "    answer_length = MAX_TOKENS - self._num_tokens_from_string(outline_prompt) - self._num_tokens_from_string(user_prompt) - 50\n",
        "\n",
        "    headers = {\"Authorization\": f\"Bearer {OPENAI_API_KEY}\",\n",
        "               \"content-type\": \"application/json\"}  \n",
        "    params = {\"model\": \"gpt-3.5-turbo\", \"messages\": messages, \"max_tokens\": answer_length // ratio, \"temperature\": 0.6}\n",
        "\n",
        "    r = requests.post(url=\"https://api.openai.com/v1/chat/completions\", json=params, headers=headers)\n",
        "    try:\n",
        "      return r.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "    except:\n",
        "      print(r.json())\n",
        "      print(self._num_tokens_from_string(user_prompt))\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6kbyOsUfoVgQ"
      },
      "outputs": [],
      "source": [
        "class Conversation:\n",
        "  def __init__(self, title, author, outline):\n",
        "    self.title = title\n",
        "    self.author = author\n",
        "    self.pages = outline.pages\n",
        "    self.page_summaries = outline.page_summaries\n",
        "    self.outline = outline.outline\n",
        "    #initial system prompt\n",
        "    self.messages = [{\"role\": \"system\", \"content\": \"You are a world class AI tutor who helps students understand their readings. The student will tell you the name of the text that they are reading. The system will provide you with a page by page summary of the text. You will engage in a socratic dialogue with the student to help them better understand the text. After the student's question, the system may provide you with a relavent text excerpt, which you should refer to.\"}]\n",
        "    #setup context for the reading\n",
        "    self.add_message(\"user\",f\"I am reading {self.title} by {self.author}\")\n",
        "    self.add_message(\"system\", f\"page_summaries:\\n{str(self.page_summaries)}\")\n",
        "    self.add_message(\"assistant\", \"Hi, I am here to help you understand your reading. You can ask me any questions you have about the reading, and I'll do my best to answer your questions!\")\n",
        "\n",
        "  def add_message(self, role, content):\n",
        "    self.messages.append({\"role\": role, \"content\": content})\n",
        "\n",
        "  def get_reply(self):\n",
        "    headers = {\"Authorization\": f\"Bearer {OPENAI_API_KEY}\",\n",
        "               \"content-type\": \"application/json\"}  \n",
        "    messages = self.messages\n",
        "\n",
        "    #try to get the relavent page number given the chat history\n",
        "    relavent_page_num = self.get_page_num()\n",
        "    try: \n",
        "      page_num = int(relavent_page_num)\n",
        "    except: \n",
        "      page_num = None\n",
        "      print(relavent_page_num)\n",
        "\n",
        "    if page_num:\n",
        "      messages.append({\"role\": \"system\", \"content\": self.pages[page_num]})\n",
        "\n",
        "    #if we run out of context size, then delete messages from the start\n",
        "    while True:\n",
        "      params = {\"model\": \"gpt-3.5-turbo\", \"messages\": messages}\n",
        "      r = requests.post(url=\"https://api.openai.com/v1/chat/completions\", json=params, headers=headers)\n",
        "      try:\n",
        "        reply = r.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "        return (reply, page_num)\n",
        "      except:\n",
        "        self.messsages = self.messages[:4] + self.messages[6:]\n",
        "        messages = self.messages\n",
        "        if page_num:\n",
        "          messages.append({\"role\": \"system\", \"content\": self.pages[page_num]})\n",
        "      \n",
        "  \n",
        "  #GPT-as-backend to determine which page number to reference given the question and given the outline\n",
        "  def get_page_num(self):\n",
        "    system_prompt = \"You are an AI teaching assistant who helps an AI teacher guide a student through their reading. You will also be provided the entire chat history between the AI teacher and the student. A page-by-page summary of the reading will be including at the beginning of the chat history. Your job is to return an integer representing the most relavant page of the reading given the chat history. You are to only return a single number. No words or other symbols.\"\n",
        "    \n",
        "    while True:\n",
        "      user_prompt = \"Chat history: \" + str(self.messages)\n",
        "      params = {\"model\": \"gpt-3.5-turbo\", \"messages\": [{\"role\": \"system\", \"content\": system_prompt}, \n",
        "                                                      {\"role\": \"user\", \"content\": user_prompt}]}\n",
        "      headers = {\"Authorization\": f\"Bearer {OPENAI_API_KEY}\",\n",
        "                \"content-type\": \"application/json\"}\n",
        "      r = requests.post(url=\"https://api.openai.com/v1/chat/completions\", json=params, headers=headers)\n",
        "\n",
        "      try:\n",
        "        page_string = r.json()[\"choices\"][0][\"message\"][\"content\"] \n",
        "        break\n",
        "      except:\n",
        "        print(\"OH NO\")\n",
        "        self.messages = self.messages[:4] + self.messages[6:]\n",
        "      \n",
        "    return int(re.search(r'\\d+', page_string).group())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNz14xJ84ZoG"
      },
      "outputs": [],
      "source": [
        "#test the backend in the notebook, without spinning up Gradio\n",
        "def run_conversation(path, title, author, outline=None): \n",
        "  print(\"type 'QUIT' to quit out of the chat.\\n\\n\")\n",
        "  print(\"starting to create outline...\")\n",
        "  if not outline:\n",
        "    outline = PDFOutline(path)\n",
        "  print(\"done creating outline:\")\n",
        "  conversation = Conversation(title, author, outline)\n",
        "  print(conversation.outline)\n",
        "  print(f\"\\n\\nAssistant: {conversation.messages[-1]['content']}\")\n",
        "  while True:\n",
        "    user_question = input(\"User: \")\n",
        "    if user_question == 'QUIT':\n",
        "      break\n",
        "    conversation.add_message(\"user\", user_question)\n",
        "    response, num = conversation.get_reply()\n",
        "    print(num)\n",
        "    conversation.add_message(\"assistant\", response)\n",
        "    print(f\"Assistant: {response}\")\n",
        "  return conversation, outline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1b-QVeoKIQp"
      },
      "source": [
        "\n",
        "# Frontend\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maah_BBoKGP5"
      },
      "outputs": [],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 655
        },
        "id": "r5nKmxUEKFKi",
        "outputId": "7ea0cfae-4a5f-4b36-c0d3-8eec378c3146"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import re\n",
        "\n",
        "def add_text(state, user_question):\n",
        "    state['conversationObj'].add_message(\"user\", user_question)\n",
        "    #try to get the page number related to the question\n",
        "    response, num = state['conversationObj'].get_reply()\n",
        "    try:\n",
        "      real_num = (int(num) * state['outline'].fake_word_rate) / state['outline'].original_word_rate\n",
        "      state['conversationObj'].add_message(\"assistant\", response)\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "      print(num)\n",
        "      state['conversationObj'].add_message(\"assistant\", response)\n",
        "    #str(conversation.get_page_num(user_question)) + \n",
        "    state['convoList'] = state['convoList'] + [(user_question, response + f\" [This answer is covered by roughly page {int(real_num)}.]\")]\n",
        "\n",
        "    return state, state['convoList']\n",
        "\n",
        "def read_PDF(state, file):\n",
        "  state['outline'] = PDFOutline(file.name)\n",
        "  state['conversationObj']= Conversation(state['title'], state['author'], state['outline'])\n",
        "  state['convoList'] = state['convoList']+ [('', state['outline'].outline)]\n",
        "  state['convoList'] = state['convoList'] + [('', \"Hi, I am here to help you understand your reading. You can ask me any questions you have about the reading, and I'll do my best to answer your questions!\")]\n",
        "  return state, state['convoList']\n",
        "\n",
        "def add_author(state, author_name):\n",
        "  state['author'] = author_name\n",
        "  return state, state['convoList']\n",
        "\n",
        "def add_title(state, title):\n",
        "  state['author'] = title\n",
        "  return state, state['convoList']\n",
        "\n",
        "\n",
        "with gr.Blocks(css=\"#chatbot .overflow-y-auto{height:500px}\") as demo:\n",
        "    chatbot = gr.Chatbot(elem_id=\"chatbot\")\n",
        "    state = gr.State({'convoList':[], 'conversationObj': None, 'outline': None, 'author':'','title':''})\n",
        "\n",
        "    with gr.Column():\n",
        "      with gr.Row(scale=0.15, min_width=0):\n",
        "          authorTxt = gr.Textbox(show_label=False, placeholder=\"Author's Name\").style(container=False)\n",
        "          titleTxt = gr.Textbox(show_label=False, placeholder=\"Title\").style(container=False)\n",
        "      with gr.Column(scale=0.85):\n",
        "          btn = gr.UploadButton(\"Upload a PDFðŸ“š\")\n",
        "      with gr.Column(scale=0.85):\n",
        "          txt = gr.Textbox(show_label=False, placeholder=\"Start chatting\").style(container=False)\n",
        "\n",
        "    txt.submit(add_text, [state, txt], [state, chatbot])\n",
        "    authorTxt.submit(add_author, [state, txt], [state, chatbot])\n",
        "    titleTxt.submit(add_title, [state, txt], [state, chatbot])\n",
        "    btn.upload(read_PDF, [state, btn], [state, chatbot])\n",
        "\n",
        "demo.launch(debug = True, share=True)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
